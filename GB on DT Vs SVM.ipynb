{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                                            learning_rate=0.1, loss='deviance',\n",
       "                                            max_depth=3, max_features=None,\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=1,\n",
       "                                            min_samples_split=2,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators=100,\n",
       "                                            n_iter_no_change=None,\n",
       "                                            presort='auto', random_state=0,\n",
       "                                            subsample=1.0, tol=0.0001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False))],\n",
       "         verbose=False)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test= pd.read_csv('test2.csv', header=None)\n",
    "df_train = pd.read_csv('train2.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.iloc[:,:-1]\n",
    "y = df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24720\n",
       "1     7841\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверим сбалансированность классов\n",
    "df_train[14].value_counts()\n",
    "#модель будет предсказывать \"0\" в 76% случаев, а '1' - в 24% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преобразуем тестовые данные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Private             24532\n",
       " Self-emp-not-inc     2541\n",
       " Local-gov            2093\n",
       " State-gov            1298\n",
       " Self-emp-inc         1116\n",
       " Federal-gov           960\n",
       " Without-pay            14\n",
       " Never-worked            7\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imr = SimpleImputer(missing_values = ' ?', strategy = 'most_frequent')\n",
    "imr.fit(X)\n",
    "train_data = imr.transform(X)\n",
    "train_data = pd.DataFrame(train_data)\n",
    "train_data[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[1,3,5,6,7,8,9,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_categ = []\n",
    "for i in range(14): \n",
    "    if i not in categorical_features:\n",
    "        not_categ.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame()\n",
    "for i in categorical_features: \n",
    "    t = pd.get_dummies(train_data[i])\n",
    "    new_data = pd.concat([new_data, pd.get_dummies(train_data[i])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in not_categ:\n",
    "    pd.concat([new_data, train_data[i]], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.drop(' Holand-Netherlands', axis=1) #этой переменной не будет в тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преобразуем тестовые данные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Private             12173\n",
       " Self-emp-not-inc     1321\n",
       " Local-gov            1043\n",
       " State-gov             683\n",
       " Self-emp-inc          579\n",
       " Federal-gov           472\n",
       " Without-pay             7\n",
       " Never-worked            3\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imr.fit(X_test)\n",
    "test_data = imr.transform(X_test)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "test_data[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = pd.DataFrame()\n",
    "for i in categorical_features: \n",
    "    t = pd.get_dummies(test_data[i])\n",
    "    new_test_data = pd.concat([new_test_data, pd.get_dummies(test_data[i])], axis=1)\n",
    "for i in not_categ:\n",
    "    pd.concat([new_test_data, test_data[i]], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 99)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Строим классификацию**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод опорных векторов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#переменных много, сократим размерность с помощью PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19653486 0.08035434 0.06831624 0.05874457 0.04849995 0.04765806\n",
      " 0.04377946 0.03576886 0.03349027 0.02626785 0.02576414 0.02560366\n",
      " 0.0228597  0.02074752 0.01967692 0.01897551 0.01598888 0.01494046\n",
      " 0.0130645  0.01191315 0.01104415 0.01090725 0.01014397 0.00980756\n",
      " 0.00905977 0.00853685 0.00798101 0.00787751 0.00765825 0.0072277 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30)\n",
    "new = pca.fit(new_data)\n",
    "\n",
    "print(new.explained_variance_ratio_)\n",
    "#как видим, нет самых ярких, наиболее значимых, признаков, в основном их совокупность оъясняет 1-2% дисперсии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#снизим размерность для ускорения подбора параметров и обучения данных\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    " \n",
    "ipca = IncrementalPCA(n_components=30)\n",
    "ipca.fit(new_data)\n",
    "IncrementalPCA(batch_size=30, n_components=2)\n",
    "t = ipca.transform(new_data) # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.DataFrame(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train, t_val, y_train, y_val = train_test_split(t, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8272939442328953"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(t_train, y_train)\n",
    "clf.score(t_val, y_val)\n",
    "#так он обучился быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#переберем параметры RandomizedGridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8210293575727797"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_val, y_val)\n",
    "#так он обучился быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "search = RandomizedSearchCV(clf, tp, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#теперь подберем параметры с помощью gridsearchCV\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                   {'kernel': ['poly'], 'degree':[3,6,10,20,100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                 coef0=0.0, decision_function_shape='ovr',\n",
       "                                 degree=3, gamma='auto_deprecated',\n",
       "                                 kernel='rbf', max_iter=-1, probability=False,\n",
       "                                 random_state=None, shrinking=True, tol=0.001,\n",
       "                                 verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'C': [1, 10, 100, 1000],\n",
       "                                        'gamma': [0.001, 0.0001],\n",
       "                                        'kernel': ['rbf']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(t_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'gamma': 0.001, 'C': 1000}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226863226863227"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_ #на бэйзлайне, совсем без подбора, было лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm =make_pipeline(StandardScaler(), SVC(kernel= 'rbf', gamma= 0.001, C=1000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(new_data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma=0.001,\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8231175531261515"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#без учета сокращения размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(new_data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#посмотрим, как будет себя вести базовая версия классификатора\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8261884289399337"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_val, y_val) #бэйзлайн для svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сравним с базовым вариантом решающих деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.827171109200344"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=0))\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "clf_tree.score(X_val, y_val)#бэйзлайн для GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**промежуточный итог**: \\\n",
    "accuracy на бэйзлайне у бустинга над деревьями: 0.827\\\n",
    "accuracy на бэйзлайне у support vector machine: 0.821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "#     \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"max_depth\":[23,25,28],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "#     \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "#     \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10,15,20,25]\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(clf, tuned_parameters, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.814641935880113"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search best_params здесь:\n",
    "clf_tree_non_scale = GradientBoostingClassifier(random_state=0, max_depth=30, n_estimators=30,learning_rate=0.3)\n",
    "clf_tree_non_scale.fit(X_train, y_train)\n",
    "\n",
    "clf_tree_non_scale.score(X_val, y_val) #very "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "так как search.best_param_ дал результат ниже, чем бэйзлайн, увеличим число ступеней бустинга (n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282766244933055"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=0,n_estimators=130))\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "clf_tree.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288907996560619"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=0,n_estimators=150))\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "clf_tree.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8298734799164722"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=0,n_estimators=200))\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "clf_tree.score(X_val, y_val)\n",
    "#the best model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13334\n",
       "1     2946\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf_tree.predict(new_test_data)\n",
    "preds = pd.DataFrame(preds)\n",
    "\n",
    "preds.to_csv('forecast_tree.csv', sep='\\t', header=None, index=None)\n",
    "df = pd.read_csv('forecast_tree.csv')\n",
    "df.iloc[:,-1].value_counts()\n",
    "\n",
    "#сохраним результат, оценим разбиение классов - пропорция, совпадает  с тренировочной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=0))\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "clf_tree.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "решающие деревья (в том числе с использованием градиентного бустинга) разделяют пространство на гипер-прямоугольники по принципу прироста информации, а метод опорных векторов использует ядерный метод,  наращивая измерения данных до тех пор, пока не найдется линейно разделяющее класссы гиперпространство. \\\n",
    "\\\n",
    "в силу большого объема номинативных переменных, обучение SVM было долгим и не очень эффективным (даже с учетом попыток сокращения размерности с помощью PCA). то же самое можно сказать и о деревьях, но благодаря увеличению стандартного количества итераций бустинга в два раза (до 200), и не меняя при этом остальные параметры, удалось на 0.3% увеличить accuracy деревьев от бэйзлайна \n",
    "\n",
    "\n",
    "**промежуточный итог**: \\\n",
    "accuracy на бэйзлайне у бустинга над деревьями: 0.827\\\n",
    "accuracy на бэйзлайне у support vector machine: 0.821\n",
    "\n",
    "accuracy итоговой модели: 0.83"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
